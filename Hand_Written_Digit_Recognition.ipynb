{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsPj1WBCixC6",
        "outputId": "949d9623-80b6-49ee-efac-a0ca9b4fff44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2376 - accuracy: 0.9311\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0996 - accuracy: 0.9692\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0710 - accuracy: 0.9776\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0535 - accuracy: 0.9829\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0435 - accuracy: 0.9858\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0347 - accuracy: 0.9888\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0290 - accuracy: 0.9907\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0262 - accuracy: 0.9913\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0216 - accuracy: 0.9929\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0207 - accuracy: 0.9929\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1078 - accuracy: 0.9761\n",
            "Test accuracy: 97.61%\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))  # Flatten the 28x28 images\n",
        "model.add(Dense(128, activation='relu'))   # First hidden layer with ReLU activation\n",
        "model.add(Dense(64, activation='relu'))    # Second hidden layer with ReLU activation\n",
        "model.add(Dense(10, activation='softmax')) # Output layer with softmax activation\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "model.save('mnist_digit_recognition_model.h5')\n"
      ]
    }
  ]
}